function net = BatchNN(TrainData,TestData,eta,Units,iterations,alpha,net)
% TRNN_train : save in the structure 'net' the variables after the training 
%              of a NN with the Time-Regularization algorithm;the structure
%              can be trained many times mantaining the data dimension
%
%     net = TRNN_train(TrainI,TrainT,TestI,TestT,eta,iterations)
%     net = TRNN_train(TrainI,TrainT,TestI,TestT,eta,iterations,net)
%     net = TRNN_train(TrainI,TrainT,TestI,TestT,eta,iterations,'momentum',alpha)
%
%     TrainI: size-by-number_of_samples matrix containg the training data
%             (without targets)
%     TrainT: number_of_classes-by-number_of_samples matrix containing 
%             binary targets for TrainI, NaN/Inf means unlabeled sample 
%     TestI: the same as TrainI for test data
%     TestT: the same as TrainT for test data(possibly unlabeled samples
%             will be removed for performance evaluation)
%     eta: learning rate
%     Units: units of the hidden layer
%     iterations: number of epochs of training over the data
%     alpha: momentum coefficient
%     net: existing structure previously initialized/trained(optional)

 
tic;    

% removing possible unlabeled samples from Test Data
TrainData=TrainData(:,isfinite(TrainData(end,:)));
TrainT=TrainT(:,isfinite(TrainT(1,:)));
Train_dim = size(TrainI); % saving data dimension 
Train_classes=TrainT(1,:); %initialization vector containing class labels
Target_dim = size(TrainT);
% saving class labels to check predictions
for i = 1:Train_dim(2)     
    Train_classes(i) = find(TrainT(:,i)==max(TrainT(:,i)));
end
% removing possible unlabeled samples from Test Data
TestI=TestI(:,isfinite(TestT(1,:)));
TestT=TestT(:,isfinite(TestT(1,:)));
Test_dim = size(TestT,2);
Test_classes(1:Test_dim)=0;
for i = 1:Test_dim
    Test_classes(i)= find(TestT(:,i)==max(TestT(:,i)));   
end

if nargin < 9
    net.MSE = zeros(1,iterations);
    net.Accuracy = zeros(1,iterations);            
    net.TestMSE= zeros(1,iterations);
    net.TestAccuracy=zeros(1,iterations);    
    net.Step=0;
    net.Units = Units;
    net.HM = rand(net.Units,(Train_dim(1)+1))*1e-3; % zero-initialization of 
                                                %hidden matrix weights
    net.OM = rand(Target_dim(1),(net.Units+1))*1e-3;% zero-initialization of 
                                               % output matrix weights     
    net.HM = net.HM-mean(mean(net.HM));
    net.OM = net.OM-mean(mean(net.OM)); 
    % gradients matrices initialization
    net.V_w = zeros(net.Units,(Train_dim(1)+1));
    net.V_c = zeros(Target_dim(1),(net.Units+1));
    % momentum gradients matrices initialization 
    net.pV_hm = zeros(net.Units,(Train_dim(1)+1));
    net.pV_om = zeros(Target_dim(1),(net.Units+1));
else 
    net.MSE=[net.MSE zeros(1,iterations)];
    net.Accuracy=[net.Accuracy zeros(1,iterations)];
    net.TestMSE=[net.TestMSE zeros(1,iterations)];
    net.TestAccuracy=[net.TestAccuracy zeros(1,iterations)];
end

net.eta = eta;

% filename to save data
etastr = num2str(eta);
if alpha ==0
    met_name = 'BNN_';
else
    m = num2str(alpha);
    m=m(m~='.');
    met_name = ['BNNm',m,'_'];
end
filename=[met_name,inputname(1),'_tau',taustr(taustr~='.'),'_eta',etastr(etastr~='.'),...
               '_HU',num2str(net.Units),'_epochs',num2str(length(net.MSE))];
iter = 0;

while iter < iterations 
    fprintf('Iterations left: %f \n',iterations-iter);    
    net.Step = net.Step+1;
    % gradients accumulation matrices initialization
    net.V_hm = zeros(net.Units,(Train_dim(1)+1));
    net.V_om = zeros(Target_dim(1),(net.Units+1));
    for k = 1:Train_dim(2)
        % forward evaluation
        [net,~,~] = TRNN_eval(net,TrainI(:,k),TrainT(:,k));
        % error accumulation
        net.V_hm = net.V_hm+ net.V_w;
        net.V_om = net.V_om+ net.V_c;
    end  
    % error backpropagation
    net.V_hm = net.V_hm / max(max(abs(net.V_hm)));
    net.V_om = net.V_om / max(max(abs(net.V_om)));
    net.pV_hm = alpha*net.pV_hm+(1-alpha)*net.V_hm ;
    net.pV_om = alpha*net.pV_om+(1-alpha)*net.V_om ;
    net.HM = net.HM - net.eta*net.pV_hm;
    net.OM = net.OM - net.eta*net.pV_om;
    % error and prediction evaluation
    iter = iter + 1;
    % performance evaluation on Training Data
    [net.MSE(net.Step),net.Accuracy(net.Step)] = ...
                 PerformanceEval(net,TrainI,TrainT,Train_classes);                                            
    % performance evaluation on Test Data
    [net.TestMSE(net.Step),net.TestAccuracy(net.Step)] = ...
                             PerformanceEval(net,TestI,TestT,Test_classes);
    fprintf('Mean Square Error= %f \n',net.MSE(net.Step));
    save(filename,'net');
end

toc;



